# YC-Go-JobScraper



> ğŸš€ An intelligent job aggregator that automatically discovers and tracks early-career opportunities from Y Combinator companies. Built with Go, powered by GitHub Actions, and hosted for free on GitHub Pages.An intelligent job scraper written in Go that discovers earlyâ€‘career roles from Greenhouse boards, stores them in SQLite, exports CSV, and serves a static dashboard via GitHub Pages.



[![Deploy Status](https://github.com/Ajiteshreddy7/YC-Golang-Scraper/workflows/Deploy%20to%20GitHub%20Pages/badge.svg)](https://github.com/Ajiteshreddy7/YC-Golang-Scraper/actions)


[![Go Version](https://img.shields.io/badge/Go-1.21%2B-00ADD8?logo=go)](https://go.dev/)- Smart scraping via Greenhouse API

- Earlyâ€‘career filtering (intern, new grad, junior) and USâ€‘location bias

## ğŸ“‹ Table of Contents- SQLite storage with deâ€‘duplication on URL

- CSV export to `data/job_applications.csv`

- [Overview](#overview)- Static website generation for GitHub Pages

- [Features](#features)- Automated daily scraping via GitHub Actions

- [Live Demo](#live-demo)- 100% free hosting 

- [Quick Start](#quick-start)

- [Installation](#installation)

- [Configuration](#configuration)

- [Usage](#usage)Visit the live dashboard at: **https://ajiteshreddy7.github.io/YC-Go-Scraper/**

- [Architecture](#architecture)

- [GitHub Pages Deployment](#github-pages-deployment) Updates automatically every day at 3 AM UTC.

# YC Job Scraper

Lightweight job aggregator for YC companies. Scrapes earlyâ€‘career roles (internships, new grad, junior) from Greenhouse, stores them in SQLite, and publishes a searchable static site on GitHub Pages.

â€¢ Live site: https://ajiteshreddy7.github.io/YC-Golang-Scraper/

## What it does

- Scrape YC company jobs via Greenhouse
- Autoâ€‘tag levels (Intern, New Grad, Entry)
- Save to SQLite and export CSV
- Generate a static dashboard with search, filters, and â€œMark Appliedâ€

## ğŸ—ï¸ Architecture

### System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      GitHub Actions                          â”‚
â”‚  (Runs daily at 3 AM UTC or on-demand via manual trigger)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   Scraper Binary     â”‚
         â”‚  (cmd/scraper)       â”‚
         â”‚                      â”‚
         â”‚ â€¢ Queries Greenhouse â”‚
         â”‚ â€¢ Filters jobs       â”‚
         â”‚ â€¢ Deduplicates       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   SQLite Database    â”‚
         â”‚   (data/jobs.db)     â”‚
         â”‚                      â”‚
         â”‚ â€¢ Job title          â”‚
         â”‚ â€¢ Company            â”‚
         â”‚ â€¢ Location           â”‚
         â”‚ â€¢ Apply URL          â”‚
         â”‚ â€¢ Posted date        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                       â”‚
        â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Static Site Gen â”‚   â”‚  CSV Exporter   â”‚
â”‚ (cmd/static)    â”‚   â”‚ (internal/exp.) â”‚
â”‚                 â”‚   â”‚                 â”‚
â”‚ â€¢ index.html    â”‚   â”‚ â€¢ job_apps.csv  â”‚
â”‚ â€¢ jobs.json     â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ â€¢ Search UI     â”‚
â”‚ â€¢ Filters       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   GitHub Pages      â”‚
â”‚                     â”‚
â”‚ â€¢ Hosts static site â”‚
â”‚ â€¢ Global CDN        â”‚
â”‚ â€¢ Free HTTPS        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

### Project Structure

```
YC-Golang-Scraper/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ deploy-pages.yml      # GitHub Actions workflow for automation
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ scraper_config.json       # List of companies to scrape
â”‚
â”œâ”€â”€ data/                         # Generated data (not in git)
â”‚   â”œâ”€â”€ jobs.db                   # SQLite database
â”‚   â””â”€â”€ job_applications.csv      # CSV export
â”‚
â”œâ”€â”€ go-scraper/                   # Go application root
â”‚   â”œâ”€â”€ cmd/
â”‚   â”‚   â”œâ”€â”€ scraper/
â”‚   â”‚   â”‚   â””â”€â”€ main.go           # CLI scraper entrypoint
â”‚   â”‚   â”œâ”€â”€ static-site/
â”‚   â”‚   â”‚   â””â”€â”€ main.go           # Static site generator
â”‚   â”‚   â””â”€â”€ dashboard/
â”‚   â”‚       â””â”€â”€ main.go           # Optional local API server
â”‚   â”‚
â”‚   â”œâ”€â”€ internal/
â”‚   â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”‚   â””â”€â”€ db.go             # SQLite connection and schema
â”‚   â”‚   â”œâ”€â”€ scraper/
â”‚   â”‚   â”‚   â”œâ”€â”€ greenhouse.go     # Greenhouse API client
â”‚   â”‚   â”‚   â”œâ”€â”€ greenhouse_test.go
â”‚   â”‚   â”‚   â””â”€â”€ greenhouse_filters_test.go
â”‚   â”‚   â”œâ”€â”€ exporter/
â”‚   â”‚   â”‚   â””â”€â”€ exporter.go       # CSV export logic
â”‚   â”‚   â””â”€â”€ logger/
â”‚   â”‚       â””â”€â”€ logger.go         # Structured logging
â”‚   â”‚
â”‚   â”œâ”€â”€ go.mod                    # Go module definition
â”‚   â””â”€â”€ go.sum                    # Dependency checksums
â”‚
â”œâ”€â”€ public/                       # Generated static site (not in git)
â”‚   â”œâ”€â”€ index.html                # Dashboard UI
â”‚   â””â”€â”€ jobs.json                 # JSON API
â”‚
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```
## Docs

- docs/quickstart.md â€“ local setup (Windows/macOS/Linux)
- docs/deployment.md â€“ GitHub Pages + workflow
- docs/configuration.md â€“ config file and env vars


## ğŸ› Troubleshooting

### Common Issues

**Issue: Scraper finds no jobs**
- Check company names in `config/scraper_config.json`
- Verify companies use Greenhouse (visit `boards.greenhouse.io/<company>`)
- Run with `LOG_LEVEL=DEBUG` for detailed output

**Issue: GitHub Pages not deploying**
- Ensure GitHub Pages is enabled (Settings â†’ Pages â†’ Source: GitHub Actions)
- Check Actions tab for deployment logs
- Verify workflow file exists at `.github/workflows/deploy-pages.yml`

**Issue: SQLite database locked**
- Close any open database connections
- Delete `jobs.db-shm` and `jobs.db-wal` files
- Restart the scraper

## ğŸ“„ License

This project is licensed under the **MIT License**.


<div align="center">

**[â¬† Back to Top](#yc-job-scraper)**



</div>
